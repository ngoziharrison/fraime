[{"key":"9CCFED8K","version":36,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/9CCFED8K","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/9CCFED8K","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Le Bui and Noble","parsedDate":"2020-07-09","numChildren":2},"data":{"key":"9CCFED8K","version":36,"itemType":"bookSection","title":"We’re Missing a Moral Framework of Justice in Artificial Intelligence: On the Limits, Failings, and Ethics of Fairness","creators":[{"creatorType":"editor","firstName":"Markus D.","lastName":"Dubber"},{"creatorType":"editor","firstName":"Frank","lastName":"Pasquale"},{"creatorType":"editor","firstName":"Sunit","lastName":"Das"},{"creatorType":"bookAuthor","firstName":"Matthew","lastName":"Le Bui"},{"creatorType":"bookAuthor","firstName":"Safiya Umoja","lastName":"Noble"},{"creatorType":"author","firstName":"Matthew","lastName":"Le Bui"},{"creatorType":"author","firstName":"Safiya Umoja","lastName":"Noble"}],"abstractNote":"This chapter assesses the concepts of fairness and bias in artificial intelligence research and interventions. In considering the explosive growth, emergence of, and investment in high-profile AI fairness and ethics interventions within both the academy and industry—alongside the mounting and proliferating calls for the interrogation, regulation, and, in some cases, dismantling and prohibition of AI—it contests and questions the extent to which such remedies can address the original concerns and problems they are designed to address. Indeed, many community organizations are organizing responses and challenging AI used in predictive technologies—facial-recognition software and biometrics technologies—with increasing success. Ultimately, the canon of AI ethics must interrogate and deeply engage with intersectional power structures that work to further consolidate capital in the hands of the elites and that will undergird digital informational systems of inequality: there is no neutral or objective state through which the flows and mechanics of data can be articulated as unbiased or fair.","bookTitle":"The Oxford Handbook of Ethics of AI","series":"","seriesNumber":"","volume":"","numberOfVolumes":"","edition":"","place":"","publisher":"Oxford University Press","date":"2020-07-09","pages":"161-179","language":"en","ISBN":"978-0-19-006739-7","shortTitle":"We’re Missing a Moral Framework of Justice in Artificial Intelligence","url":"https://academic.oup.com/edited-volume/34287/chapter/290660537","accessDate":"2024-04-11T07:45:47Z","archive":"","archiveLocation":"","libraryCatalog":"DOI.org (Crossref)","callNumber":"","rights":"","extra":"DOI: 10.1093/oxfordhb/9780190067397.013.9","tags":[{"tag":"Ethics"}],"collections":[],"relations":{"owl:sameAs":"http://zotero.org/groups/5808972/items/NA8AS6E6"},"dateAdded":"2025-04-27T20:52:37Z","dateModified":"2025-04-28T05:31:35Z"}},{"key":"NLH894CV","version":35,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/NLH894CV","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/NLH894CV","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Chen and Metcalf","numChildren":1},"data":{"key":"NLH894CV","version":35,"itemType":"journalArticle","title":"Explainer: A Sociotechnical Approach to AI Policy","creators":[{"creatorType":"author","firstName":"Brian J","lastName":"Chen"},{"creatorType":"author","firstName":"Jacob","lastName":"Metcalf"}],"abstractNote":"","publicationTitle":"","volume":"","issue":"","pages":"","date":"","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"","language":"en","DOI":"","ISSN":"","shortTitle":"","url":"","accessDate":"","archive":"","archiveLocation":"","libraryCatalog":"Zotero","callNumber":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:18:08Z","dateModified":"2025-04-28T05:18:08Z"}},{"key":"HWJ6KCV6","version":33,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/HWJ6KCV6","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/HWJ6KCV6","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Tacheva and Ramasubramanian","parsedDate":"2023-07-01","numChildren":2},"data":{"key":"HWJ6KCV6","version":33,"itemType":"journalArticle","title":"AI Empire: Unraveling the interlocking systems of oppression in generative AI's global order","creators":[{"creatorType":"author","firstName":"Jasmina","lastName":"Tacheva"},{"creatorType":"author","firstName":"Srividya","lastName":"Ramasubramanian"}],"abstractNote":"As artificial intelligence (AI) continues to captivate the collective imagination through the latest generation of generative AI models such as DALL-E and ChatGPT, the dehumanizing and harmful features of the technology industry that have plagued it since its inception only seem to deepen and intensify. Far from a “glitch” or unintentional error, these endemic issues are a function of the interlocking systems of oppression upon which AI is built. Using the analytical framework of “Empire,” this paper demonstrates that we live not simply in the “age of AI” but in the age of AI Empire. Specifically, we show that this networked and distributed global order is rooted in heteropatriarchy, racial capitalism, white supremacy, and coloniality and perpetuates its influence through the mechanisms of extractivism, automation, essentialism, surveillance, and containment. Therefore, we argue that any attempt at reforming AI from within the same interlocking oppressive systems that created it is doomed to failure and, moreover, risks exacerbating existing harm. Instead, to advance justice, we must radically transform not just the technology itself, but our ideas about it, and develop it from the bottom up, from the perspectives of those who stand the most risk of being harmed.","publicationTitle":"Big Data & Society","volume":"10","issue":"2","pages":"20539517231219241","date":"2023-07-01","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"","language":"en","DOI":"10.1177/20539517231219241","ISSN":"2053-9517","shortTitle":"AI Empire","url":"https://doi.org/10.1177/20539517231219241","accessDate":"2024-03-03T18:23:55Z","archive":"","archiveLocation":"","libraryCatalog":"SAGE Journals","callNumber":"","rights":"","extra":"Publisher: SAGE Publications Ltd","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:17:53Z","dateModified":"2025-04-28T05:17:53Z"}},{"key":"3HHSRIS9","version":28,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/3HHSRIS9","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/3HHSRIS9","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Mökander et al.","parsedDate":"2023","numChildren":1},"data":{"key":"3HHSRIS9","version":28,"itemType":"journalArticle","title":"The Switch, the Ladder, and the Matrix: Models for Classifying AI Systems","creators":[{"creatorType":"author","firstName":"Jakob","lastName":"Mökander"},{"creatorType":"author","firstName":"Margi","lastName":"Sheth"},{"creatorType":"author","firstName":"David S.","lastName":"Watson"},{"creatorType":"author","firstName":"Luciano","lastName":"Floridi"}],"abstractNote":"Organisations that design and deploy artificial intelligence (AI) systems increasingly commit themselves to high-level, ethical principles. However, there still exists a gap between principles and practices in AI ethics. One major obstacle organisations face when attempting to operationalise AI Ethics is the lack of a well-defined material scope. Put differently, the question to which systems and processes AI ethics principles ought to apply remains unanswered. Of course, there exists no universally accepted definition of AI, and different systems pose different ethical challenges. Nevertheless, pragmatic problem-solving demands that things should be sorted so that their grouping will promote successful actions for some specific end. In this article, we review and compare previous attempts to classify AI systems for the purpose of implementing AI governance in practice. We find that attempts to classify AI systems proposed in previous literature use one of three mental models: the Switch, i.e., a binary approach according to which systems either are or are not considered AI systems depending on their characteristics; the Ladder, i.e., a risk-based approach that classifies systems according to the ethical risks they pose; and the Matrix, i.e., a multi-dimensional classification of systems that take various aspects into account, such as context, input data, and decision-model. Each of these models for classifying AI systems comes with its own set of strengths and weaknesses. By conceptualising different ways of classifying AI systems into simple mental models, we hope to provide organisations that design, deploy, or regulate AI systems with the vocabulary needed to demarcate the material scope of their AI governance frameworks.","publicationTitle":"Minds and Machines","volume":"33","issue":"1","pages":"221-248","date":"03/2023","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"Minds & Machines","language":"en","DOI":"10.1007/s11023-022-09620-y","ISSN":"0924-6495, 1572-8641","shortTitle":"The Switch, the Ladder, and the Matrix","url":"https://link.springer.com/10.1007/s11023-022-09620-y","accessDate":"2023-11-12T19:57:40Z","archive":"","archiveLocation":"","libraryCatalog":"DOI.org (Crossref)","callNumber":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:07:23Z","dateModified":"2025-04-28T05:07:23Z"}},{"key":"AH7NM2UX","version":27,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/AH7NM2UX","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/AH7NM2UX","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Ojewale et al.","parsedDate":"2024-02-27","numChildren":1},"data":{"key":"AH7NM2UX","version":27,"itemType":"preprint","title":"Towards AI Accountability Infrastructure: Gaps and Opportunities in AI Audit Tooling","creators":[{"creatorType":"author","firstName":"Victor","lastName":"Ojewale"},{"creatorType":"author","firstName":"Ryan","lastName":"Steed"},{"creatorType":"author","firstName":"Briana","lastName":"Vecchione"},{"creatorType":"author","firstName":"Abeba","lastName":"Birhane"},{"creatorType":"author","firstName":"Inioluwa Deborah","lastName":"Raji"}],"abstractNote":"Audits are critical mechanisms for identifying the risks and limitations of deployed artificial intelligence (AI) systems. However, the effective execution of AI audits remains incredibly difficult. As a result, practitioners make use of various tools to support their efforts. Drawing on interviews with 35 AI audit practitioners and a landscape analysis of 390 tools, we map the current ecosystem of available AI audit tools. While there are many tools designed to assist practitioners with setting standards and evaluating AI systems, these tools often fell short of supporting the accountability goals of AI auditing in practice. We thus highlight areas for future tool development beyond evaluation -- from harms discovery to advocacy -- and outline challenges practitioners faced in their efforts to use AI audit tools. We conclude that resources are lacking to adequately support the full scope of needs for many AI audit practitioners and recommend that the field move beyond tools for just evaluation, towards more comprehensive infrastructure for AI accountability.","genre":"","repository":"arXiv","archiveID":"arXiv:2402.17861","place":"","date":"2024-02-27","series":"","seriesNumber":"","DOI":"","citationKey":"","url":"http://arxiv.org/abs/2402.17861","accessDate":"2024-03-01T21:14:51Z","archive":"","archiveLocation":"","shortTitle":"Towards AI Accountability Infrastructure","language":"","libraryCatalog":"arXiv.org","callNumber":"","rights":"","extra":"arXiv:2402.17861 [cs]","tags":[{"tag":"Computer Science - Computers and Society","type":1}],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:07:14Z","dateModified":"2025-04-28T05:07:14Z"}},{"key":"9BIPKJPQ","version":26,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/9BIPKJPQ","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/9BIPKJPQ","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"van Rooij et al.","parsedDate":"2024-09-27","numChildren":1},"data":{"key":"9BIPKJPQ","version":26,"itemType":"journalArticle","title":"Reclaiming AI as a Theoretical Tool for Cognitive Science","creators":[{"creatorType":"author","firstName":"Iris","lastName":"van Rooij"},{"creatorType":"author","firstName":"Olivia","lastName":"Guest"},{"creatorType":"author","firstName":"Federico","lastName":"Adolfi"},{"creatorType":"author","firstName":"Ronald","lastName":"de Haan"},{"creatorType":"author","firstName":"Antonina","lastName":"Kolokolova"},{"creatorType":"author","firstName":"Patricia","lastName":"Rich"}],"abstractNote":"The idea that human cognition is, or can be understood as, a form of computation is a useful conceptual tool for cognitive science. It was a foundational assumption during the birth of cognitive science as a multidisciplinary field, with Artificial Intelligence (AI) as one of its contributing fields. One conception of AI in this context is as a provider of computational tools (frameworks, concepts, formalisms, models, proofs, simulations, etc.) that support theory building in cognitive science. The contemporary field of AI, however, has taken the theoretical possibility of explaining human cognition as a form of computation to imply the practical feasibility of realising human(-like or -level) cognition in factual computational systems, and the field frames this realisation as a short-term inevitability. Yet, as we formally prove herein, creating systems with human(-like or -level) cognition is intrinsically computationally intractable. This means that any factual AI systems created in the short-run are at best decoys. When we think these systems capture something deep about ourselves and our thinking, we induce distorted and impoverished images of ourselves and our cognition. In other words, AI in current practice is deteriorating our theoretical understanding of cognition rather than advancing and enhancing it. The situation could be remediated by releasing the grip of the currently dominant view on AI and by returning to the idea of AI as a theoretical tool for cognitive science. In reclaiming this older idea of AI, however, it is important not to repeat conceptual mistakes of the past (and present) that brought us to where we are today.","publicationTitle":"Computational Brain & Behavior","volume":"","issue":"","pages":"","date":"2024-09-27","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"Comput Brain Behav","language":"en","DOI":"10.1007/s42113-024-00217-5","ISSN":"2522-087X","shortTitle":"","url":"https://doi.org/10.1007/s42113-024-00217-5","accessDate":"2024-09-30T01:41:34Z","archive":"","archiveLocation":"","libraryCatalog":"Springer Link","callNumber":"","rights":"","extra":"","tags":[{"tag":"Artificial Intelligence","type":1},{"tag":"Artificial Intelligence (AI)","type":1},{"tag":"Cognitive science","type":1},{"tag":"Computational complexity","type":1},{"tag":"Engineering","type":1},{"tag":"Explanation","type":1},{"tag":"Theory","type":1}],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:07:04Z","dateModified":"2025-04-28T05:07:04Z"}},{"key":"GJYNBHXV","version":25,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/GJYNBHXV","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/GJYNBHXV","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Sherman et al.","parsedDate":"2024","numChildren":1},"data":{"key":"GJYNBHXV","version":25,"itemType":"conferencePaper","title":"The Power of Absence: Thinking with Archival Theory in Algorithmic Design","creators":[{"creatorType":"author","firstName":"Jihan","lastName":"Sherman"},{"creatorType":"author","firstName":"Romi","lastName":"Morrison"},{"creatorType":"author","firstName":"Lauren","lastName":"Klein"},{"creatorType":"author","firstName":"Daniela","lastName":"Rosner"}],"abstractNote":"This paper explores the value of archival theory as a means of grappling with bias in algorithmic design. Rather than seek to mitigate biases perpetuated by datasets and algorithmic systems, archival theory ofers a reframing of bias itself. Drawing on a range of archival theory from the felds of history, literary and cultural studies, Black studies, and feminist STS, we propose absence—as power, presence, and productive—as a concept that might more securely anchor investigations into the causes of algorithmic bias, and that can prompt more capacious, creative, and joyful future work. This essay, in turn, can intervene into the technical as well as the social, historical, and political structures that serve as sources of bias.","date":"07/2024","proceedingsTitle":"Designing Interactive Systems Conference","conferenceName":"DIS '24: Designing Interactive Systems Conference","place":"IT University of Copenhagen Denmark","publisher":"ACM","volume":"","pages":"214-223","series":"","language":"en","DOI":"10.1145/3643834.3660690","ISBN":"979-8-4007-0583-0","shortTitle":"The Power of Absence","url":"https://dl.acm.org/doi/10.1145/3643834.3660690","accessDate":"2025-02-27T21:06:13Z","archive":"","archiveLocation":"","libraryCatalog":"DOI.org (Crossref)","callNumber":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:06:48Z","dateModified":"2025-04-28T05:06:48Z"}},{"key":"JAFDNQNA","version":21,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/JAFDNQNA","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/JAFDNQNA","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Whittaker","parsedDate":"2023-05-17","numChildren":1},"data":{"key":"JAFDNQNA","version":21,"itemType":"webpage","title":"Origin Stories: Plantations, Computers, and Industrial Control","creators":[{"creatorType":"author","firstName":"Meredith","lastName":"Whittaker"}],"abstractNote":"The proto-Taylorist methods of worker control Charles Babbage encoded into his calculating engines have origins in plantation management.","websiteTitle":"Logic(s) Magazine","websiteType":"","date":"5/17/2023","shortTitle":"Origin Stories","url":"https://logicmag.io/supa-dupa-skies/origin-stories-plantations-computers-and-industrial-control/","accessDate":"2023-08-12T23:38:46Z","language":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:04:05Z","dateModified":"2025-04-28T05:04:05Z"}},{"key":"3FFQGSYY","version":20,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/3FFQGSYY","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/3FFQGSYY","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Paullada et al.","parsedDate":"2021","numChildren":1},"data":{"key":"3FFQGSYY","version":20,"itemType":"journalArticle","title":"Data and its (dis)contents: A survey of dataset development and use in machine learning research","creators":[{"creatorType":"author","firstName":"Amandalynne","lastName":"Paullada"},{"creatorType":"author","firstName":"Inioluwa Deborah","lastName":"Raji"},{"creatorType":"author","firstName":"Emily M.","lastName":"Bender"},{"creatorType":"author","firstName":"Emily","lastName":"Denton"},{"creatorType":"author","firstName":"Alex","lastName":"Hanna"}],"abstractNote":"In this work, we survey a breadth of literature that has revealed the limitations of predominant practices for dataset collection and use in the ﬁeld of machine learning. We cover studies that critically review the design and development of datasets with a focus on negative societal impacts and poor outcomes for system performance. We also cover approaches to ﬁltering and augmenting data and modeling techniques aimed at mitigating the impact of bias in datasets. Finally, we discuss works that have studied data practices, cultures, and disciplinary norms and discuss implications for the legal, ethical, and functional challenges the ﬁeld continues to face. Based on these ﬁndings, we advocate for the use of both qualitative and quantitative approaches to more carefully document and analyze datasets during the creation and usage phases.","publicationTitle":"Patterns","volume":"2","issue":"11","pages":"100336","date":"11/2021","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"Patterns","language":"en","DOI":"10.1016/j.patter.2021.100336","ISSN":"26663899","shortTitle":"Data and its (dis)contents","url":"https://linkinghub.elsevier.com/retrieve/pii/S2666389921001847","accessDate":"2024-04-12T17:09:10Z","archive":"","archiveLocation":"","libraryCatalog":"DOI.org (Crossref)","callNumber":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:03:49Z","dateModified":"2025-04-28T05:03:49Z"}},{"key":"EBAV6ATQ","version":19,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/EBAV6ATQ","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/EBAV6ATQ","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Denton et al.","parsedDate":"2021","numChildren":1},"data":{"key":"EBAV6ATQ","version":19,"itemType":"journalArticle","title":"On the genealogy of machine learning datasets: A critical history of ImageNet","creators":[{"creatorType":"author","firstName":"Emily","lastName":"Denton"},{"creatorType":"author","firstName":"Alex","lastName":"Hanna"},{"creatorType":"author","firstName":"Razvan","lastName":"Amironesei"},{"creatorType":"author","firstName":"Andrew","lastName":"Smart"},{"creatorType":"author","firstName":"Hilary","lastName":"Nicole"}],"abstractNote":"In response to growing concerns of bias, discrimination, and unfairness perpetuated by algorithmic systems, the datasets used to train and evaluate machine learning models have come under increased scrutiny. Many of these examinations have focused on the contents of machine learning datasets, finding glaring underrepresentation of minoritized groups. In contrast, relatively little work has been done to examine the norms, values, and assumptions embedded in these datasets. In this work, we conceptualize machine learning datasets as a type of informational infrastructure, and motivate a genealogy as method in examining the histories and modes of constitution at play in their creation. We present a critical history of ImageNet as an exemplar, utilizing critical discourse analysis of major texts around ImageNet’s creation and impact. We find that assumptions around ImageNet and other large computer vision datasets more generally rely on three themes: the aggregation and accumulation of more data, the computational construction of meaning, and making certain types of data labor invisible. By tracing the discourses that surround this influential benchmark, we contribute to the ongoing development of the standards and norms around data development in machine learning and artificial intelligence research.","publicationTitle":"Big Data & Society","volume":"8","issue":"2","pages":"205395172110359","date":"07/2021","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"Big Data & Society","language":"en","DOI":"10.1177/20539517211035955","ISSN":"2053-9517, 2053-9517","shortTitle":"On the genealogy of machine learning datasets","url":"http://journals.sagepub.com/doi/10.1177/20539517211035955","accessDate":"2024-04-12T17:09:12Z","archive":"","archiveLocation":"","libraryCatalog":"DOI.org (Crossref)","callNumber":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:03:41Z","dateModified":"2025-04-28T05:03:41Z"}},{"key":"KB6UEQEG","version":17,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/KB6UEQEG","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/KB6UEQEG","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Scheuerman et al.","parsedDate":"2021-10-13","numChildren":1},"data":{"key":"KB6UEQEG","version":17,"itemType":"journalArticle","title":"Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development","creators":[{"creatorType":"author","firstName":"Morgan Klaus","lastName":"Scheuerman"},{"creatorType":"author","firstName":"Alex","lastName":"Hanna"},{"creatorType":"author","firstName":"Emily","lastName":"Denton"}],"abstractNote":"MORGAN KLAUS SCHEUERMAN∗, University of Colorado Boulder, USA EMILY DENTON, Google Research, USA ALEX HANNA, Google Research, USA Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision’s propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation—how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process. CCS Concepts: • Human-centered computing → Collaborative and social computing; • Computing methodologies → Artificial intelligence.","publicationTitle":"Proceedings of the ACM on Human-Computer Interaction","volume":"5","issue":"CSCW2","pages":"1-37","date":"2021-10-13","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"Proc. ACM Hum.-Comput. Interact.","language":"en","DOI":"10.1145/3476058","ISSN":"2573-0142","shortTitle":"Do Datasets Have Politics?","url":"https://dl.acm.org/doi/10.1145/3476058","accessDate":"2024-04-12T17:09:14Z","archive":"","archiveLocation":"","libraryCatalog":"DOI.org (Crossref)","callNumber":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:03:22Z","dateModified":"2025-04-28T05:03:22Z"}},{"key":"4RIEVWE6","version":14,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/4RIEVWE6","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/4RIEVWE6","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Birhane et al.","parsedDate":"2022-06-21","numChildren":3},"data":{"key":"4RIEVWE6","version":14,"itemType":"preprint","title":"The Values Encoded in Machine Learning Research","creators":[{"creatorType":"author","firstName":"Abeba","lastName":"Birhane"},{"creatorType":"author","firstName":"Pratyusha","lastName":"Kalluri"},{"creatorType":"author","firstName":"Dallas","lastName":"Card"},{"creatorType":"author","firstName":"William","lastName":"Agnew"},{"creatorType":"author","firstName":"Ravit","lastName":"Dotan"},{"creatorType":"author","firstName":"Michelle","lastName":"Bao"}],"abstractNote":"Machine learning currently exerts an outsized influence on the world, increasingly affecting institutional practices and impacted communities. It is therefore critical that we question vague conceptions of the field as value-neutral or universally beneficial, and investigate what specific values the field is advancing. In this paper, we first introduce a method and annotation scheme for studying the values encoded in documents such as research papers. Applying the scheme, we analyze 100 highly cited machine learning papers published at premier machine learning conferences, ICML and NeurIPS. We annotate key features of papers which reveal their values: their justification for their choice of project, which attributes of their project they uplift, their consideration of potential negative consequences, and their institutional affiliations and funding sources. We find that few of the papers justify how their project connects to a societal need (15\\%) and far fewer discuss negative potential (1\\%). Through line-by-line content analysis, we identify 59 values that are uplifted in ML research, and, of these, we find that the papers most frequently justify and assess themselves based on Performance, Generalization, Quantitative evidence, Efficiency, Building on past work, and Novelty. We present extensive textual evidence and identify key themes in the definitions and operationalization of these values. Notably, we find systematic textual evidence that these top values are being defined and applied with assumptions and implications generally supporting the centralization of power.Finally, we find increasingly close ties between these highly cited papers and tech companies and elite universities.","genre":"","repository":"arXiv","archiveID":"arXiv:2106.15590","place":"","date":"2022-06-21","series":"","seriesNumber":"","DOI":"10.48550/arXiv.2106.15590","citationKey":"","url":"http://arxiv.org/abs/2106.15590","accessDate":"2023-04-07T18:08:12Z","archive":"","archiveLocation":"","shortTitle":"","language":"","libraryCatalog":"arXiv.org","callNumber":"","rights":"","extra":"arXiv:2106.15590 [cs]","tags":[{"tag":"Computer Science - Artificial Intelligence","type":1},{"tag":"Computer Science - Computers and Society","type":1},{"tag":"Computer Science - Machine Learning","type":1}],"collections":[],"relations":{},"dateAdded":"2025-04-28T05:03:09Z","dateModified":"2025-04-28T05:03:09Z"}},{"key":"CW5ELV2E","version":11,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/CW5ELV2E","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/CW5ELV2E","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Bender et al.","parsedDate":"2021-03-01","numChildren":1},"data":{"key":"CW5ELV2E","version":11,"itemType":"conferencePaper","title":"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜","creators":[{"creatorType":"author","firstName":"Emily M.","lastName":"Bender"},{"creatorType":"author","firstName":"Timnit","lastName":"Gebru"},{"creatorType":"author","firstName":"Angelina","lastName":"McMillan-Major"},{"creatorType":"author","firstName":"Shmargaret","lastName":"Shmitchell"}],"abstractNote":"The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.","date":"March 1, 2021","proceedingsTitle":"Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency","conferenceName":"","place":"New York, NY, USA","publisher":"Association for Computing Machinery","volume":"","pages":"610–623","series":"FAccT '21","language":"","DOI":"10.1145/3442188.3445922","ISBN":"978-1-4503-8309-7","shortTitle":"On the Dangers of Stochastic Parrots","url":"https://dl.acm.org/doi/10.1145/3442188.3445922","accessDate":"2023-10-11","archive":"","archiveLocation":"","libraryCatalog":"ACM Digital Library","callNumber":"","rights":"","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T00:57:28Z","dateModified":"2025-04-28T00:57:28Z"}},{"key":"L3QLJZPL","version":7,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/L3QLJZPL","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/L3QLJZPL","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Gebru and Torres","parsedDate":"2024-04-14","numChildren":1},"data":{"key":"L3QLJZPL","version":7,"itemType":"journalArticle","title":"The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence","creators":[{"creatorType":"author","firstName":"Timnit","lastName":"Gebru"},{"creatorType":"author","firstName":"Émile P.","lastName":"Torres"}],"abstractNote":"The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.","publicationTitle":"First Monday","volume":"","issue":"","pages":"","date":"2024-04-14","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"","language":"en","DOI":"10.5210/fm.v29i4.13636","ISSN":"1396-0466","shortTitle":"The TESCREAL bundle","url":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","accessDate":"2024-04-17T19:17:40Z","archive":"","archiveLocation":"","libraryCatalog":"firstmonday.org","callNumber":"","rights":"Copyright (c) 2024 First Monday","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-28T00:44:50Z","dateModified":"2025-04-28T00:44:50Z"}},{"key":"MAC7UUZ5","version":2,"library":{"type":"group","id":5969464,"name":"fraime research repository","links":{"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository","type":"text/html"}}},"links":{"self":{"href":"https://api.zotero.org/groups/5969464/items/MAC7UUZ5","type":"application/json"},"alternate":{"href":"https://www.zotero.org/groups/fraime_research_repository/items/MAC7UUZ5","type":"text/html"}},"meta":{"createdByUser":{"id":12181477,"username":"kingnegritude","name":"","links":{"alternate":{"href":"https://www.zotero.org/kingnegritude","type":"text/html"}}},"creatorSummary":"Ahmed et al.","parsedDate":"2024-04-14","numChildren":1},"data":{"key":"MAC7UUZ5","version":2,"itemType":"journalArticle","title":"Field-building and the epistemic culture of AI safety","creators":[{"creatorType":"author","firstName":"Shazeda","lastName":"Ahmed"},{"creatorType":"author","firstName":"Klaudia","lastName":"Jaźwińska"},{"creatorType":"author","firstName":"Archana","lastName":"Ahlawat"},{"creatorType":"author","firstName":"Amy","lastName":"Winecoff"},{"creatorType":"author","firstName":"Mona","lastName":"Wang"}],"abstractNote":"The emerging field of “AI safety” has attracted public attention and large infusions of capital to support its implied promise: the ability to deploy advanced artificial intelligence (AI) while reducing its gravest risks. Ideas from effective altruism, longtermism, and the study of existential risk are foundational to this new field. In this paper, we contend that overlapping communities interested in these ideas have merged into what we refer to as the broader “AI safety epistemic community,” which is sustained through its mutually reinforcing community-building and knowledge production practices. We support this assertion through an analysis of four core sites in this community’s epistemic culture: 1) online community-building through Web forums and career advising; 2) AI forecasting; 3) AI safety research; and 4) prize competitions. The dispersal of this epistemic community’s members throughout the tech industry, academia, and policy organizations ensures their continued input into global discourse about AI. Understanding the epistemic culture that fuses their moral convictions and knowledge claims is crucial to evaluating these claims, which are gaining influence in critical, rapidly changing debates about the harms of AI and how to mitigate them.","publicationTitle":"First Monday","volume":"","issue":"","pages":"","date":"2024-04-14","series":"","seriesTitle":"","seriesText":"","journalAbbreviation":"","language":"en","DOI":"10.5210/fm.v29i4.13626","ISSN":"1396-0466","shortTitle":"","url":"https://firstmonday.org/ojs/index.php/fm/article/view/13626","accessDate":"2024-12-04T16:13:19Z","archive":"","archiveLocation":"","libraryCatalog":"firstmonday.org","callNumber":"","rights":"Copyright (c) 2024 © 2024, Shazeda Ahmed, Klaudia Jaźwińska, Archana Ahlawat, Amy Winecoff, and Mona Wang","extra":"","tags":[],"collections":[],"relations":{},"dateAdded":"2025-04-27T20:52:04Z","dateModified":"2025-04-27T20:52:04Z"}}]
script.js:15:15
We’re Missing a Moral Framework of Justice in Artificial Intelligence: On the Limits, Failings, and Ethics of Fairness script.js:23:11
Explainer: A Sociotechnical Approach to AI Policy script.js:23:11
AI Empire: Unraveling the interlocking systems of oppression in generative AI's global order script.js:23:11
The Switch, the Ladder, and the Matrix: Models for Classifying AI Systems script.js:23:11
Towards AI Accountability Infrastructure: Gaps and Opportunities in AI Audit Tooling script.js:23:11
Reclaiming AI as a Theoretical Tool for Cognitive Science script.js:23:11
The Power of Absence: Thinking with Archival Theory in Algorithmic Design script.js:23:11
Origin Stories: Plantations, Computers, and Industrial Control script.js:23:11
Data and its (dis)contents: A survey of dataset development and use in machine learning research script.js:23:11
On the genealogy of machine learning datasets: A critical history of ImageNet script.js:23:11
Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development script.js:23:11
The Values Encoded in Machine Learning Research script.js:23:11
On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜 script.js:23:11
The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence script.js:23:11
Field-building and the epistemic culture of AI safety script.js:23:11


